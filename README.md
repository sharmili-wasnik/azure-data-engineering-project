# Azure Data Engineering Portfolio Project
End-to-End Azure Data Engineering Portfolio Project

## Project Overview
This project demonstrates an end-to-end Azure Data Engineering pipeline for ingesting, transforming, and analyzing sales data using Azure Data Factory, Azure Databricks, PySpark, SQL, and Python.

## Business Problem
A retail company wants to process sales data to understand revenue trends by product category.

## Architecture Flow
CSV Data → Azure Data Factory → Azure Data Lake → Azure Databricks (PySpark) → Delta Lake → SQL Analytics

## Key Features
- Data ingestion pipeline
- Python ETL processing
- PySpark big-data transformations
- SQL analytical queries
- Delta Lake optimized storage

## Technologies Used
- Python
- SQL
- PySpark
- Azure Data Factory
- Azure Databricks
- Azure Data Lake

## How to Run
1. Place dataset in /data
2. Run python_etl.py
3. Run pyspark_transform.py
4. Execute SQL analysis queries

## Skills Demonstrated
- Cloud ETL pipelines
- Big data transformation
- Data modeling
- Performance optimization
- Azure ecosystem

## Author
Sharmili Wasnik — Aspiring Azure Data Engineer
